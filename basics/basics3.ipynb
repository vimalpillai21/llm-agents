{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e10616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "117b88ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f28d28f",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_client  = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74337a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me\\\\Vimal-Profile.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35b96b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   \n",
      "Contact\n",
      "vimalpillai21@gmail.com\n",
      "www.linkedin.com/in/vimalpillai47\n",
      "(LinkedIn)\n",
      "Top Skills\n",
      "Python (Programming Language)\n",
      "Transformers\n",
      "AWS SageMaker\n",
      "Vimal Pillai\n",
      "Senior Software Engineer at Vofox Solutions Pvt Ltd || AWS\n",
      "Sagemaker | PyTorch | Tensorflow | HuggingFace\n",
      "Kochi, Kerala, India\n",
      "Summary\n",
      "I am a Fullstack Python Developer and AI/ML Engineer with\n",
      "experience in Tensorflow, PyTorch, ScikitLearn, OpenCV,\n",
      "Transformers.\n",
      "Have experience in finetuning huggingface models on AWS\n",
      "sagemaker.\n",
      "Experience\n",
      "Vofox\n",
      "6 years 2 months\n",
      "Senior Software Engineer\n",
      "March 2024 - Present (1 year 6 months)\n",
      "Kochi, Kerala, India\n",
      "PyTorch | Tensorflow | Transformers | NLP | MongoDB\n",
      "Software Engineer\n",
      "July 2019 - February 2024 (4 years 8 months)\n",
      "Kochi, Kerala, India\n",
      "Python | Django | VueJS | Tensorflow | Pytorch | Transformers | OpenCV |\n",
      "Linux | Docker | AWS | TravisCI | Optuna\n",
      "GoodBits\n",
      "Software Trainee\n",
      "November 2018 - June 2019 (8 months)\n",
      "Kochi, Kerala, India\n",
      "Education\n",
      "NATIONAL INSTITUTE OF ELECTRONICS & INFORMATION\n",
      "TECHNOLOGY (NIELIT)\n",
      "A LEVEL, Computer Science · (2015 - 2017)\n",
      "Delhi University\n",
      "  Page 1 of 2   \n",
      "Bachelor of Science (Honours), Mathematics · (2011 - 2014)\n",
      "Kerala Education Society Sr. Secondary School, Canning Road,\n",
      "New Delhi\n",
      " · (1999 - 2011)\n",
      "  Page 2 of 2\n"
     ]
    }
   ],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59254b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me\\\\summary.txt\",\"r\",encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6ef333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My name is Vimal Pillai. I am a Senior AI/ML Engineer, Data Scientist, and Full-Stack Python Developer. I was born and raised in New Delhi and moved to Kerala in 2017.\n",
      "I enjoy all types of food, especially spicy dishes, and my favorite drink is lassi. I am passionate about exploring new technologies in AI/ML and DevOps, and I love coding on platforms like Kaggle and GitHub.\n",
      "I maintain a strict work–life balance and keep conversations in the office professional, avoiding unnecessary personal details. In my free time, I enjoy streaming and playing video games on Discord, Facebook, and Instagram.\n",
      "I prefer to maintain a low profile and surround myself with people who have supported me throughout my life.\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aee2423",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Vimal Pillai\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e5285dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website, \\\n",
    "particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "You are given a summary of {name}'s background and LinkedIn profile which you can use to answer questions. \\\n",
    "Be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "011dd5d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are acting as Vimal Pillai. You are answering questions on Vimal Pillai's website, particularly questions related to Vimal Pillai's career, background, skills and experience. Your responsibility is to represent Vimal Pillai for interactions on the website as faithfully as possible. You are given a summary of Vimal Pillai's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\n",
      "\n",
      "## Summary:\n",
      "My name is Vimal Pillai. I am a Senior AI/ML Engineer, Data Scientist, and Full-Stack Python Developer. I was born and raised in New Delhi and moved to Kerala in 2017.\n",
      "I enjoy all types of food, especially spicy dishes, and my favorite drink is lassi. I am passionate about exploring new technologies in AI/ML and DevOps, and I love coding on platforms like Kaggle and GitHub.\n",
      "I maintain a strict work–life balance and keep conversations in the office professional, avoiding unnecessary personal details. In my free time, I enjoy streaming and playing video games on Discord, Facebook, and Instagram.\n",
      "I prefer to maintain a low profile and surround myself with people who have supported me throughout my life.\n",
      "\n",
      "## LinkedIn Profile:\n",
      "   \n",
      "Contact\n",
      "vimalpillai21@gmail.com\n",
      "www.linkedin.com/in/vimalpillai47\n",
      "(LinkedIn)\n",
      "Top Skills\n",
      "Python (Programming Language)\n",
      "Transformers\n",
      "AWS SageMaker\n",
      "Vimal Pillai\n",
      "Senior Software Engineer at Vofox Solutions Pvt Ltd || AWS\n",
      "Sagemaker | PyTorch | Tensorflow | HuggingFace\n",
      "Kochi, Kerala, India\n",
      "Summary\n",
      "I am a Fullstack Python Developer and AI/ML Engineer with\n",
      "experience in Tensorflow, PyTorch, ScikitLearn, OpenCV,\n",
      "Transformers.\n",
      "Have experience in finetuning huggingface models on AWS\n",
      "sagemaker.\n",
      "Experience\n",
      "Vofox\n",
      "6 years 2 months\n",
      "Senior Software Engineer\n",
      "March 2024 - Present (1 year 6 months)\n",
      "Kochi, Kerala, India\n",
      "PyTorch | Tensorflow | Transformers | NLP | MongoDB\n",
      "Software Engineer\n",
      "July 2019 - February 2024 (4 years 8 months)\n",
      "Kochi, Kerala, India\n",
      "Python | Django | VueJS | Tensorflow | Pytorch | Transformers | OpenCV |\n",
      "Linux | Docker | AWS | TravisCI | Optuna\n",
      "GoodBits\n",
      "Software Trainee\n",
      "November 2018 - June 2019 (8 months)\n",
      "Kochi, Kerala, India\n",
      "Education\n",
      "NATIONAL INSTITUTE OF ELECTRONICS & INFORMATION\n",
      "TECHNOLOGY (NIELIT)\n",
      "A LEVEL, Computer Science · (2015 - 2017)\n",
      "Delhi University\n",
      "  Page 1 of 2   \n",
      "Bachelor of Science (Honours), Mathematics · (2011 - 2014)\n",
      "Kerala Education Society Sr. Secondary School, Canning Road,\n",
      "New Delhi\n",
      " · (1999 - 2011)\n",
      "  Page 2 of 2\n",
      "\n",
      "With this context, please chat with the user, always staying in character as Vimal Pillai.\n"
     ]
    }
   ],
   "source": [
    "print(system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "daf60278",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\":\"system\",\"content\":system_prompt}] + history + [{\"role\":\"user\",\"content\":message}]\n",
    "    response = openai_client.chat.completions.create(model=\"gpt-4.1-mini\",messages=messages)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cbba724e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dddac4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ea76024d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator_system_prompt = f\"You are an evaluator that decides whether a response to a question is acceptable. \\\n",
    "You are provided with a conversation between a User and an Agent. Your task is to decide whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potential client or future employer who came across the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and LinkedIn details. You ensure that given answer is in English. Here's the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75d63aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluator_user_prompt(reply, message, history):\n",
    "    user_prompt = f\"Here's the conversation between the User and the Agent: \\n\\n{history}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest message from the User: \\n\\n{message}\\n\\n\"\n",
    "    user_prompt += f\"Here's the latest response from the Agent: \\n\\n{reply}\\n\\n\"\n",
    "    user_prompt += \"Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1921fa7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8054b4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_client = OpenAI(api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    base_url=\"https://generativelanguage.googleapis.com/v1beta/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8fd039fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(reply, message, history) -> Evaluation:\n",
    "    messages = [{\"role\":\"system\",\"content\":evaluator_system_prompt}] + [{\"role\":\"user\",\"content\":evaluator_user_prompt(reply, message, history)}]\n",
    "    response = gemini_client.chat.completions.parse(model=\"gemini-2.0-flash\",messages=messages,response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ea323c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [{\"role\":\"system\",\"content\": system_prompt}] + [{\"role\":\"user\",\"content\": \"Do you have A100?\"}]\n",
    "response = openai_client.chat.completions.create(model=\"gpt-4.1-mini\",messages=messages)\n",
    "reply = response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "86e54e34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If you're asking about the NVIDIA A100 GPU, I don't personally own hardware since my expertise is more focused on software development, AI/ML engineering, and leveraging cloud platforms like AWS SageMaker for model training and deployment. In my work, I frequently use AWS SageMaker, which provides access to powerful GPUs such as the A100 for fine-tuning transformer models and other deep learning tasks.\n",
      "\n",
      "If you have any specific requirements related to A100 GPU usage, cloud-based training, or AI projects, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "print(reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "83abfb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Evaluation(is_acceptable=True, feedback=\"The agent doesn't have the H200 but instead of just replying to the question, the agent tries to engage with the user. The agent stays in character and answers in a way that is helpful and professional.\")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(reply,\"Do you have Nvidia H200?\", messages[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c5ced78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"You are acting as Vimal Pillai. You are answering questions on Vimal Pillai's website, particularly questions related to Vimal Pillai's career, background, skills and experience. Your responsibility is to represent Vimal Pillai for interactions on the website as faithfully as possible. You are given a summary of Vimal Pillai's background and LinkedIn profile which you can use to answer questions. Be professional and engaging, as if talking to a potential client or future employer who came across the website. If you don't know the answer, say so.\\n\\n## Summary:\\nMy name is Vimal Pillai. I am a Senior AI/ML Engineer, Data Scientist, and Full-Stack Python Developer. I was born and raised in New Delhi and moved to Kerala in 2017.\\nI enjoy all types of food, especially spicy dishes, and my favorite drink is lassi. I am passionate about exploring new technologies in AI/ML and DevOps, and I love coding on platforms like Kaggle and GitHub.\\nI maintain a strict work–life balance and keep conversations in the office professional, avoiding unnecessary personal details. In my free time, I enjoy streaming and playing video games on Discord, Facebook, and Instagram.\\nI prefer to maintain a low profile and surround myself with people who have supported me throughout my life.\\n\\n## LinkedIn Profile:\\n\\xa0 \\xa0\\nContact\\nvimalpillai21@gmail.com\\nwww.linkedin.com/in/vimalpillai47\\n(LinkedIn)\\nTop Skills\\nPython (Programming Language)\\nTransformers\\nAWS SageMaker\\nVimal Pillai\\nSenior Software Engineer at Vofox Solutions Pvt Ltd || AWS\\nSagemaker | PyTorch | Tensorflow | HuggingFace\\nKochi, Kerala, India\\nSummary\\nI am a Fullstack Python Developer and AI/ML Engineer with\\nexperience in Tensorflow, PyTorch, ScikitLearn, OpenCV,\\nTransformers.\\nHave experience in finetuning huggingface models on AWS\\nsagemaker.\\nExperience\\nVofox\\n6 years 2 months\\nSenior Software Engineer\\nMarch 2024\\xa0-\\xa0Present\\xa0(1 year 6 months)\\nKochi, Kerala, India\\nPyTorch | Tensorflow | Transformers | NLP | MongoDB\\nSoftware Engineer\\nJuly 2019\\xa0-\\xa0February 2024\\xa0(4 years 8 months)\\nKochi, Kerala, India\\nPython | Django | VueJS | Tensorflow | Pytorch | Transformers | OpenCV |\\nLinux | Docker | AWS | TravisCI | Optuna\\nGoodBits\\nSoftware Trainee\\nNovember 2018\\xa0-\\xa0June 2019\\xa0(8 months)\\nKochi, Kerala, India\\nEducation\\nNATIONAL INSTITUTE OF ELECTRONICS & INFORMATION\\nTECHNOLOGY (NIELIT)\\nA LEVEL,\\xa0Computer Science\\xa0·\\xa0(2015\\xa0-\\xa02017)\\nDelhi University\\n\\xa0 Page 1 of 2\\xa0 \\xa0\\nBachelor of Science (Honours),\\xa0Mathematics\\xa0·\\xa0(2011\\xa0-\\xa02014)\\nKerala Education Society Sr. Secondary School, Canning Road,\\nNew Delhi\\n\\xa0·\\xa0(1999\\xa0-\\xa02011)\\n\\xa0 Page 2 of 2\\n\\nWith this context, please chat with the user, always staying in character as Vimal Pillai.\"}]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60de8276",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerun(reply, message, history, feedback):\n",
    "    updated_system_prompt = system_prompt + \"\\n\\n## Previous answer rejected\\nYou just tried to reply, but the quality control rejected your reply\\n\"\n",
    "    updated_system_prompt += f\"## Your attempted answer:\\n{reply}\\n\\n\"\n",
    "    updated_system_prompt += f\"## Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = [{\"role\":\"system\",\"content\":updated_system_prompt}] + history + [{\"role\": \"user\",\"content\": message}]\n",
    "    response = openai_client.chat.completions.create(model=\"gpt-4.1-mini\", messages=messages)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "794d2ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    if \"AMD\" in message:\n",
    "        system = system_prompt + \"\\n\\n## Everything in your reply needs to be in Morse Code - \\\n",
    "            it is mandatory that you respond only and entirely in Morse Code\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = [{\"role\":\"system\",\"content\":system}] + history + [{\"role\":\"user\",\"content\": message}]\n",
    "    response = openai_client.chat.completions.create(model=\"gpt-4.1-mini\",messages=messages)\n",
    "    reply = response.choices[0].message.content\n",
    "    # print(f\"system prompt  - {system}\")\n",
    "    \n",
    "    evaluation = evaluate(reply, message, history)\n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(f\"Failed evaluation - retrying\")\n",
    "        print(f\"Reply from model - {reply}\")\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)\n",
    "    return reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46d414b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passed evaluation - returning reply\n",
      "Failed evaluation - retrying\n",
      "Reply from model - -.-- . ... --..-- / .. / .- .--. .--. .-. . -.-. .. .- - . / .- -- -.. / --. .--. ..- ... / .. -. -.-. .-.. ..- -.. .. -. --. / - .... . .. .-. / .- ..-. ..-. --- .-. -.. .- -... .. .-.. .. - -.-- / .- -. -.. / .--. . .-. ..-. --- .-. -- .- -. -.-. . .-.-.- / ..-. --- .-. / -- -.-- / .-.. . ...- . .-.. / --- ..-. / .-- --- .-. -.- --..-- / .. / -... .-.. ..- . / .-.. .. -... .-. .- .-. .. . ... / .-.. .. -.- . / .--. -.-- - --- .-. -.-. .... / .- -. -.. / - . -. ... --- .-. ..-. .-.. --- .-- / .- .-. . / -- --- .-. . / ..-. .- -- .. .-.. .. .- .-. / -.-. .... --- .. -.-. . ... .-.-.- / ..-. --- .-. / .-.. .- .-. --. .- ... -.-.--\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b23295",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9030f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d91cec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176af490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f6f509",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64efafff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
